{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from astropy import units as u\n",
    "import pandas as pd\n",
    "from scipy.interpolate import interp1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lsst.geom import Point2D, Point2I\n",
    "from lsst.afw.cameraGeom import FIELD_ANGLE, PIXELS\n",
    "import lsst.afw.cameraGeom.utils as cgUtils\n",
    "from lsst.daf.persistence import Butler, NoResults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lsst.syseng.throughputs as st\n",
    "from lsst.sims.photUtils import PhotometricParameters, Bandpass, LSSTdefaults\n",
    "from lsst.sims.utils import angularSeparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rname = 'R10'\n",
    "#rname = 'R22'\n",
    "#rname = 'R01'\n",
    "#rname = 'R11'\n",
    "#rname = 'R20'\n",
    "#rname = 'R21'\n",
    "rname = 'R30'\n",
    "#rname = 'R12'\n",
    "#rname = 'R02'\n",
    "#rname = 'R31'\n",
    "#rname = 'R03'\n",
    "#rname = 'R34'\n",
    "#rname = 'R13'\n",
    "#rname = 'R23'\n",
    "#rname = 'R14'\n",
    "#rname = 'R32'\n",
    "#rname = 'R24'\n",
    "#rname = 'R41'\n",
    "#rname = 'R42'\n",
    "#rname = 'R33'\n",
    "#rname = 'R43'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mapping based on \n",
    "#https://confluence.slac.stanford.edu/pages/viewpage.action?spaceKey=LSSTCAM&title=Raft+Delivery+and+Acceptance+Testing+Status\n",
    "dd = pd.read_csv('raftInstall.csv',index_col=0)\n",
    "useDefault = False\n",
    "try:\n",
    "    if np.isnan(dd.rtm[rname]):\n",
    "        useDefault = True\n",
    "        print('no data yet, use default')\n",
    "except TypeError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Default photometric parameters, as used in standard m5 calculations\n",
    "Note that effarea is not in this list here, because it varies with field.\n",
    "\n",
    "The read noise is not in this list either, because it varies by amp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exptime=15 \n",
    "nexp=2\n",
    "othernoise=0 \n",
    "darkcurrent=0.2\n",
    "X=1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we do not need this cell to calculate m5, but these FWHMeff are the default values we use actually\n",
    "lsstDefaults = LSSTdefaults()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up throughputs for hardware and atmosphere. Use the default detector QE as in syseng_throughput for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add losses to each component?\n",
    "addLosses = True\n",
    "defaultDirs = st.setDefaultDirs()\n",
    "defaultDirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "atmos = st.readAtmosphere(defaultDirs['atmosphere'], atmosFile='atmos_10_aerosol.dat')\n",
    "mirror1 = st.buildMirror(defaultDirs['mirror1'], addLosses)\n",
    "mirror2 = st.buildMirror(defaultDirs['mirror2'], addLosses)\n",
    "mirror3 = st.buildMirror(defaultDirs['mirror3'], addLosses)\n",
    "lens1 = st.buildLens(defaultDirs['lens1'], addLosses)\n",
    "lens2 = st.buildLens(defaultDirs['lens2'], addLosses)\n",
    "lens3 = st.buildLens(defaultDirs['lens3'], addLosses)\n",
    "filters = st.buildFilters(defaultDirs['filters'], addLosses)\n",
    "\n",
    "vendor = dd.vendor[rname]\n",
    "vendorDir = defaultDirs['detector']+'/../'+vendor.lower()\n",
    "addLosses = False \n",
    "detector0 = st.buildDetector(vendorDir, addLosses) #design QE from this vendor\n",
    "detector = Bandpass()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in filters:\n",
    "    print(f, lsstDefaults.FWHMeff(f), lsstDefaults.m5(f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Butler access to the QE data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATADIR = f\"{os.environ['OBS_LSST_DIR']}/lsstcam/CALIB\" \n",
    "print(DATADIR)\n",
    "butler = Butler(DATADIR)\n",
    "cam = butler.get('camera')\n",
    "\n",
    "#This is no longer needed after tickets/DM-22605\n",
    "#from lsst.obs.lsst.lsstCamMapper import LsstCamMapper\n",
    "#mapper = LsstCamMapper()\n",
    "#lsstcam = mapper.camera"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare vignetting function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# below we use v3.11 values\n",
    "vfile = f\"{os.environ['HOME']}/notebooks/f_factors/data/vignettingF.txt\"\n",
    "M1D = 8.36 #clear aperture as in Optical design\n",
    "aa = np.loadtxt(vfile, skiprows=12)\n",
    "vr = aa[:,0]\n",
    "vv = aa[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the dataframes for this raft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filterlist = tuple([s for s in filters]+['fS']) # this would be in different order than below\n",
    "filterlist = ['u', 'g', 'r', 'i', 'z', 'y', 'fS', 'u1', 'u2']\n",
    "alist = ('raDeg', 'decDeg', 'radDeg', 'effarea', 'readnoise', 'gain', 'saturation')\n",
    "detectors = []\n",
    "for det in cam:\n",
    "    rname1, dname = det.getName().split('_')\n",
    "    if rname1 != rname: \n",
    "        continue;\n",
    "    detectors.append(det.getName())\n",
    "adf = pd.DataFrame(index=alist, columns=detectors, dtype=object)\n",
    "m5df = pd.DataFrame(index=filterlist, columns=detectors, dtype=object)\n",
    "Tdf = pd.DataFrame(index=filterlist[:6], columns=detectors, dtype=object)\n",
    "Sdf = pd.DataFrame(index=filterlist[:6], columns=detectors, dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for det in cam:\n",
    "    rname1, dname = det.getName().split('_')\n",
    "    if rname1 != rname: \n",
    "        continue;\n",
    "    key = rname+'_'+dname\n",
    "    raDeg = {}\n",
    "    decDeg = {}\n",
    "    readnoise = {}\n",
    "    gain = {}\n",
    "    saturation = {}\n",
    "    for amp in det:\n",
    "        i = amp.getName()\n",
    "        amp_point = amp.getBBox().getCenter()\n",
    "        raDec = det.transform(amp_point, PIXELS, FIELD_ANGLE) \n",
    "        [raDeg[i], decDeg[i]] = np.degrees(raDec)\n",
    "        gain[i] = amp.getGain()\n",
    "        saturation[i] = amp.getSaturation()\n",
    "        #print(key, i, raDec, amp.getGain(), amp.getSaturation())\n",
    "        if useDefault:\n",
    "            readnoise[i] = 8.8\n",
    "        else:\n",
    "            readnoise[i] = amp.getReadNoise()\n",
    "    adf[key].loc['raDeg'] = list(raDeg.values())\n",
    "    adf[key].loc['decDeg'] = list(decDeg.values())\n",
    "    adf[key].loc['readnoise'] = list(readnoise.values())\n",
    "    adf[key].loc['gain'] = list(gain.values())\n",
    "    adf[key].loc['saturation'] = list(saturation.values())\n",
    "    \n",
    "    #effective area\n",
    "    radius = angularSeparation(0., 0., adf[key]['raDeg'], adf[key]['decDeg'])\n",
    "    adf[key].loc['radDeg'] = list(radius)\n",
    "    adf[key].loc['effarea'] = list(np.interp(radius, vr, vv)*np.pi*(M1D/2)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adf['R30_S00'].loc['raDeg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adf['R32_S11'].loc['readnoise']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ampList = list(raDeg.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is needed if there are only 6 QE measurements per amp\n",
    "idx = np.where(detector0.sb>0.01)\n",
    "idx1=idx[0][0]-1\n",
    "idx2=idx[0][-1]+1\n",
    "\n",
    "x1 = detector0.wavelen[idx1]\n",
    "y1 = detector0.sb[idx1]\n",
    "x2 = detector0.wavelen[idx2]\n",
    "y2 = detector0.sb[idx2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m5SRD = np.array([23.9, 25.0, 24.7, 24.0, 23.3, 22.1])\n",
    "#m5SRDmin = []\n",
    "# Nv1 from SRD table 24\n",
    "Nv1 = np.array([56, 80, 184, 184, 160, 160])\n",
    "omega = Nv1/sum(Nv1)\n",
    "fidx = 'ugrizy' #very important!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for det in cam:\n",
    "    rname1, dname = det.getName().split('_')\n",
    "    if rname1 != rname: \n",
    "        continue;\n",
    "        \n",
    "    vendor = det.getSerial()[:3].lower()\n",
    "    assert useDefault or dd.vendor[rname].lower() == vendor\n",
    "    vendorDir = defaultDirs['detector']+'/../'+vendor\n",
    "    print('Calculating m5 for %s_%s'%(rname,dname))\n",
    "    \n",
    "    key = rname+'_'+dname\n",
    "    for f in filterlist:\n",
    "        m5df[key][f] = [-1.]*len(ampList)\n",
    "    for f in filterlist[:6]:\n",
    "        Tdf[key][f] = [-1.]*len(ampList)\n",
    "        Sdf[key][f] = [-1.]*len(ampList)\n",
    "        \n",
    "    for amp in det:\n",
    "        \n",
    "        try:\n",
    "            qe_curve = butler.get('qe_curve', raftName=rname, detectorName=dname, calibDate='1970-01-01T00:00:00')\n",
    "            wavelen = detector0.wavelen \n",
    "\n",
    "            k = amp.getName()\n",
    "            if len(qe_curve.data[k][0])>10:\n",
    "                wlen = qe_curve.data[k][0]\n",
    "                eff = qe_curve.data[k][1]\n",
    "                f = interp1d(wlen.value, eff.value, fill_value=0, bounds_error=False, kind='quadratic')\n",
    "            else:\n",
    "                aa = np.append(x1, qe_curve.data[k][0].value)\n",
    "                aa = np.append(aa, x2)\n",
    "                wlen = aa * qe_curve.data[k][0].unit\n",
    "\n",
    "                aa = np.append(y1, qe_curve.data[k][1].value)\n",
    "                aa = np.append(aa, y2)\n",
    "                eff = aa * qe_curve.data[k][1].unit\n",
    "                f = interp1d(wlen.value, eff.value, fill_value=0, bounds_error=False, kind='slinear')#quadratic causes overshoot\n",
    "            \n",
    "            sb = f(wavelen)*0.01\n",
    "            #alternatively we could do (only for >10 QE measurements)\n",
    "            #amp_point = amp.getBBox().getCenter()\n",
    "            #sb = qe_curve.evaluate(det, amp_point, wavelen* u.nm, kind='quadratic').value*.01 #unit was percent in CALIB data\n",
    "\n",
    "            sb[np.isnan(sb)] = 0\n",
    "            if np.max(sb)>1.5:\n",
    "                print('These seem too LARGE ', k)\n",
    "                print(np.max(sb))\n",
    "                sb = 0\n",
    "            if np.max(sb)<0.2: #3 dead channels, 1 out of each of R01, R10, and R30; see camera confluence page table\n",
    "                print('dead channel: %s %s, max sb = %.2f'%(key, amp.getName(), np.max(sb)))\n",
    "                continue;\n",
    "                \n",
    "            detector.setBandpass(wavelen, sb)\n",
    "                \n",
    "            #detector losses  \n",
    "            #os.listdir(vendorDir)\n",
    "            detLosses = Bandpass()\n",
    "            detLosses.readThroughput(os.path.join(vendorDir, '%s_Losses/det_Losses.dat' % (vendor)))\n",
    "                \n",
    "            #build hardware and system\n",
    "            hardware = {}\n",
    "            system = {}\n",
    "            for f in filters:\n",
    "                sb = mirror1.sb * mirror2.sb *mirror3.sb\n",
    "                sb *= lens1.sb * lens2.sb * lens3.sb * filters[f].sb\n",
    "                sb *= detector.sb * detLosses.sb\n",
    "                \n",
    "                hardware[f] = Bandpass()\n",
    "                hardware[f].setBandpass(wavelen, sb)\n",
    "                system[f] = Bandpass()\n",
    "                system[f].setBandpass(wavelen, sb * atmos.sb)\n",
    "                \n",
    "        except NoResults:\n",
    "            if not useDefault:\n",
    "                print('No results found for this detector')\n",
    "            assert useDefault\n",
    "            \n",
    "            hardware, system = st.buildHardwareAndSystem(defaultDirs)\n",
    "            \n",
    "        #calculate m5      \n",
    "        iamp = ampList.index(amp.getName())\n",
    "        effarea = adf[key]['effarea'][iamp]*100**2 #convert to cm^2\n",
    "        readnoise = adf[key]['readnoise'][iamp]\n",
    "        \n",
    "        m5 = st.makeM5(hardware, system, darksky=None, \n",
    "                    exptime=15, nexp=2, readnoise=readnoise, othernoise=0, darkcurrent=0.2,\n",
    "                    effarea=effarea, X=1.0)\n",
    "        for f in filters:\n",
    "            m5df[key][f][iamp] = m5.m5[f]\n",
    "            Tdf[key][f][iamp] = m5.Tb[f]\n",
    "            Sdf[key][f][iamp] = m5.Sb[f]\n",
    "        m5amp = np.array([m5.m5[f] for f in fidx])\n",
    "        if np.all(m5amp>0):\n",
    "            m5df[key]['fS'][iamp] = sum(omega*10**(0.8*(m5amp - m5SRD)))\n",
    "        \n",
    "        #what about u-band with 1min & 2 min visits?\n",
    "        m5 = st.makeM5(hardware, system, darksky=None, \n",
    "                    exptime=30, nexp=2, readnoise=readnoise, othernoise=0, darkcurrent=0.2,\n",
    "                    effarea=effarea, X=1.0)\n",
    "        m5df[key]['u1'][iamp] = m5.m5['u']\n",
    "        m5 = st.makeM5(hardware, system, darksky=None, \n",
    "                    exptime=60, nexp=2, readnoise=readnoise, othernoise=0, darkcurrent=0.2,\n",
    "                    effarea=effarea, X=1.0)\n",
    "        m5df[key]['u2'][iamp] = m5.m5['u']        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m5df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfDir = os.path.join('m5_output', rname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(dfDir):\n",
    "    os.mkdir(dfDir)\n",
    "dfPath = os.path.join(dfDir, 'adf_%s.csv'%rname)\n",
    "adf.to_csv(dfPath)\n",
    "dfPath = os.path.join(dfDir, 'm5df_%s.csv'%rname)\n",
    "m5df.to_csv(dfPath)\n",
    "dfPath = os.path.join(dfDir, 'Tdf_%s.csv'%rname)\n",
    "Tdf.to_csv(dfPath)\n",
    "dfPath = os.path.join(dfDir, 'Sdf_%s.csv'%rname)\n",
    "Sdf.to_csv(dfPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make sure we can read out the dataframes correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ast import literal_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfPath = os.path.join(dfDir, 'adf_%s.csv'%rname)\n",
    "df = pd.read_csv(dfPath, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['%s_S00'%rname].apply(literal_eval)#['readnoise'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adf['R30_S00'].loc['raDeg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfPath = os.path.join(dfDir, 'm5df_%s.csv'%rname)\n",
    "df = pd.read_csv(dfPath, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['%s_S00'%rname].apply(literal_eval)#['readnoise'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['R01_S11']['u']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LSST",
   "language": "python",
   "name": "lsst"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
